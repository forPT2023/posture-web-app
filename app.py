import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import os
import time
from PIL import Image
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase

# OpenCVã®ã‚¨ãƒ©ãƒ¼ã‚’å›é¿ã™ã‚‹ãŸã‚ã®ç’°å¢ƒå¤‰æ•°è¨­å®š
os.environ["OPENCV_VIDEOIO_PRIORITY_MSMF"] = "0"

# MediaPipeã®Poseãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
mp_pose = mp.solutions.pose
pose = mp_pose.Pose()
mp_drawing = mp.solutions.drawing_utils

# Streamlitã®è¨­å®š
st.set_page_config(page_title="å§¿å‹¢åˆ†æã‚¢ãƒ—ãƒª", layout="centered")
st.title("ğŸ“¸ ç«‹ä½å§¿å‹¢ï¼ˆçŸ¢çŠ¶é¢ï¼‰åˆ†æã‚¢ãƒ—ãƒª")
st.write("ã‚«ãƒ¡ãƒ©ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«å§¿å‹¢ã‚’è§£æã—ã¾ã™ï¼")

# å´é¢é¸æŠ
side_option = st.radio("å´é¢ã‚’é¸æŠ", ("å·¦å´é¢", "å³å´é¢"))
st.text(f"ç¾åœ¨ã®å´é¢: {side_option}")

# ä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
save_path = "captured_images"
os.makedirs(save_path, exist_ok=True)

# ç”»åƒã®åˆæœŸåŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³
clear_images = st.checkbox("ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«å‰å›ã®ç”»åƒã‚’æ¶ˆå»ã™ã‚‹", value=True)
if clear_images:
    for file_name in ["before.png", "after.png", "comparison.png"]:
        file_path = os.path.join(save_path, file_name)
        if os.path.exists(file_path):
            os.remove(file_path)

# çŸ¢çŠ¶é¢ç”¨ã®ãƒãƒ¼ã‚«ãƒ¼ã‚»ãƒƒãƒˆ
LEFT_SAGITTAL_MARKERS = [
    mp_pose.PoseLandmark.LEFT_EAR, mp_pose.PoseLandmark.LEFT_SHOULDER,
    mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.LEFT_KNEE,
    mp_pose.PoseLandmark.LEFT_ANKLE
]
RIGHT_SAGITTAL_MARKERS = [
    mp_pose.PoseLandmark.RIGHT_EAR, mp_pose.PoseLandmark.RIGHT_SHOULDER,
    mp_pose.PoseLandmark.RIGHT_HIP, mp_pose.PoseLandmark.RIGHT_KNEE,
    mp_pose.PoseLandmark.RIGHT_ANKLE
]

# OpenCVã‚’ä½¿ç”¨ã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚¯ãƒ©ã‚¹
class VideoTransformer(VideoTransformerBase):
    def __init__(self):
        self.pose = mp_pose.Pose()

    def transform(self, frame):
        img = frame.to_ndarray(format="bgr24")
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        results = self.pose.process(img_rgb)
        height, width, _ = img.shape

        if results.pose_landmarks:
            selected_markers = LEFT_SAGITTAL_MARKERS if side_option == "å·¦å´é¢" else RIGHT_SAGITTAL_MARKERS
            points = {}
            for marker in selected_markers:
                lm = results.pose_landmarks.landmark[marker]
                cx, cy = int(lm.x * width), int(lm.y * height)
                points[marker] = (cx, cy)
                cv2.circle(img, (cx, cy), 12, (255, 255, 255), -1)
                cv2.circle(img, (cx, cy), 8, (255, 0, 0), -1)

            for i in range(len(selected_markers) - 1):
                if selected_markers[i] in points and selected_markers[i + 1] in points:
                    cv2.line(img, points[selected_markers[i]], points[selected_markers[i + 1]], (173, 216, 230), 3)

        return img

# WebRTCã«ã‚ˆã‚‹ã‚«ãƒ¡ãƒ©èµ·å‹•
webrtc_ctx = webrtc_streamer(
    key="å§¿å‹¢åˆ†æ",
    video_processor_factory=VideoTransformer,
    async_processing=True
)

# ãƒ“ãƒ•ã‚©ãƒ¼ã‚¢ãƒ•ã‚¿ãƒ¼æ©Ÿèƒ½
before_image_path = os.path.join(save_path, "before.png")
after_image_path = os.path.join(save_path, "after.png")
comparison_image_path = os.path.join(save_path, "comparison.png")

col1, col2 = st.columns(2)

with col1:
    if st.button("ğŸ“¸ ãƒ“ãƒ•ã‚©ãƒ¼ã‚’æ’®å½±"):
        if webrtc_ctx.video_processor:
            frame = webrtc_ctx.video_processor.transform(webrtc_ctx.video_transformer.last_frame)
            if frame is not None:
                Image.fromarray(frame).save(before_image_path)
                st.success("ãƒ“ãƒ•ã‚©ãƒ¼ç”»åƒã‚’æ’®å½±ã—ã¾ã—ãŸï¼")
        else:
            st.warning("ã‚«ãƒ¡ãƒ©ãŒèµ·å‹•ã—ã¦ã„ã¾ã›ã‚“ã€‚")

with col2:
    if st.button("ğŸ“· ã‚¢ãƒ•ã‚¿ãƒ¼ã‚’æ’®å½±ï¼†æ¯”è¼ƒ"):
        if webrtc_ctx.video_processor:
            frame = webrtc_ctx.video_processor.transform(webrtc_ctx.video_transformer.last_frame)
            if frame is not None:
                Image.fromarray(frame).save(after_image_path)
                st.success("ã‚¢ãƒ•ã‚¿ãƒ¼ç”»åƒã‚’æ’®å½±ã—ã¾ã—ãŸï¼")
        else:
            st.warning("ã‚«ãƒ¡ãƒ©ãŒèµ·å‹•ã—ã¦ã„ã¾ã›ã‚“ã€‚")

# ç”»åƒè¡¨ç¤ºã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
if os.path.exists(before_image_path):
    before_image = Image.open(before_image_path)
    st.image(before_image, caption="ãƒ“ãƒ•ã‚©ãƒ¼", use_container_width=True)
    st.download_button("ğŸ“¥ ãƒ“ãƒ•ã‚©ãƒ¼ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=open(before_image_path, "rb").read(), file_name="before.png", mime="image/png")

if os.path.exists(after_image_path):
    after_image = Image.open(after_image_path)
    st.image(after_image, caption="ã‚¢ãƒ•ã‚¿ãƒ¼", use_container_width=True)
    st.download_button("ğŸ“¥ ã‚¢ãƒ•ã‚¿ãƒ¼ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=open(after_image_path, "rb").read(), file_name="after.png", mime="image/png")

    if os.path.exists(before_image_path):
        before_np = np.array(before_image)
        after_np = np.array(after_image)

        if before_np.shape != after_np.shape:
            height = min(before_np.shape[0], after_np.shape[0])
            width = min(before_np.shape[1], after_np.shape[1])
            before_np = cv2.resize(before_np, (width, height))
            after_np = cv2.resize(after_np, (width, height))

        comparison_image = np.hstack((before_np, after_np))
        Image.fromarray(comparison_image).save(comparison_image_path)

        comparison_pil = Image.open(comparison_image_path)
        st.image(comparison_pil, caption="ãƒ“ãƒ•ã‚©ãƒ¼ã‚¢ãƒ•ã‚¿ãƒ¼æ¯”è¼ƒ", use_container_width=True)
        st.download_button("ğŸ“¥ ãƒ“ãƒ•ã‚©ãƒ¼ã‚¢ãƒ•ã‚¿ãƒ¼ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=open(comparison_image_path, "rb").read(), file_name="comparison.png", mime="image/png")

